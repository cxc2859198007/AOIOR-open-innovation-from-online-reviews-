{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f39fa8c-5fd3-444f-8681-dc44f3f2be63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-large').to(device)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "pos_set = ['ADJ', 'ADV', 'INTJ', 'NOUN', 'PRON', 'VERB', 'ADP', 'AUX', 'CCONJ', 'DET', 'PRON', 'SCONJ', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed26154-fb07-4699-8b6b-3968202ac04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(text, p1):\n",
    "    doc = nlp(text)\n",
    "    result_words = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.pos_ in pos_set and random.random() < p1:\n",
    "            masked_text = text[:token.idx] + '<mask>' + text[token.idx + len(token.text):]\n",
    "            # print(masked_text)\n",
    "            input_ids = tokenizer.encode(masked_text, return_tensors='pt').to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "            \n",
    "            mask_index = torch.where(input_ids[0] == tokenizer.mask_token_id)[0]\n",
    "            predictions = outputs[0][0, mask_index, :].topk(3)\n",
    "            predicted_token_indexes = predictions[1].tolist()\n",
    "\n",
    "            predicted_token_index = random.choice(predicted_token_indexes[0])\n",
    "            predicted_token = tokenizer.decode([predicted_token_index]).strip()\n",
    "            # print(f\"{token.text} --> {predicted_token}\")\n",
    "            \n",
    "            result_words.append(predicted_token)\n",
    "        else:\n",
    "            result_words.append(token.text)\n",
    "    \n",
    "    sentence = ''\n",
    "    for word in result_words:\n",
    "        if sentence and word in ',.;!?':\n",
    "            sentence += word\n",
    "        else:\n",
    "            sentence += (' ' + word if sentence else word)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6918fdf3-fb5e-4610-8d87-56be721c53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_insertion(text, p2):\n",
    "    doc = nlp(text)\n",
    "    result_words = text.split()\n",
    "    insertions = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.pos_ in pos_set and random.random() < p2:\n",
    "            masked_text = text[:token.idx] + '<mask>' + text[token.idx + len(token.text):]\n",
    "            # print(masked_text)\n",
    "            input_ids = tokenizer.encode(masked_text, return_tensors='pt').to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids)\n",
    "            \n",
    "            mask_index = torch.where(input_ids[0] == tokenizer.mask_token_id)[0]\n",
    "            predictions = outputs[0][0, mask_index, :].topk(3)\n",
    "            predicted_token_indexes = predictions[1].tolist()\n",
    "\n",
    "            predicted_token_index = random.choice(predicted_token_indexes[0])\n",
    "            predicted_token = tokenizer.decode([predicted_token_index]).strip()\n",
    "            # print(f\"Inserting: {token.text} --> {predicted_token}\")\n",
    "            \n",
    "            insertions.append(predicted_token)\n",
    "    \n",
    "    for insertion in insertions:\n",
    "        insert_position = random.randint(0, len(result_words))\n",
    "        result_words.insert(insert_position, insertion)\n",
    "    \n",
    "    return ' '.join(result_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d5559d-f95d-4750-b0f5-9bf9f345d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(text, p3):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    valid_tokens = [token for token in doc if not token.is_stop and token.pos_ in pos_set]\n",
    "    swap_cnt = int(len(valid_tokens) * p3)\n",
    "    \n",
    "    for _ in range(swap_cnt):\n",
    "        token1 = random.choice(valid_tokens)\n",
    "        token2 = random.choice(valid_tokens)\n",
    "        \n",
    "        text = text.replace(token1.text, \"_TEMP_\", 1)\n",
    "        text = text.replace(token2.text, token1.text, 1)\n",
    "        text = text.replace(\"_TEMP_\", token2.text, 1)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15d7a49-c629-41c0-926c-fc63fc406fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(text, p4):\n",
    "    doc = nlp(text)\n",
    "    result_words = [token.text for token in doc if token.is_stop or random.random() >= p4]\n",
    "    \n",
    "    sentence = ''\n",
    "    for word in result_words:\n",
    "        if sentence and word in ',.;!?':\n",
    "            sentence += word\n",
    "        else:\n",
    "            sentence += (' ' + word if sentence else word)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c804ba2-718b-4cee-8b97-af6590afff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = \"This game sets a new benchmark for open-world exploration, with a sprawling gallery of monsters each with their own unique moveset, secrets, puzzles and challenging bosses all with intricately woven lore and questlines. The map is vast end littered with content that will keep you engaged throughout the game. From Software has truely made a compelling and challenging game that leaves you wanting more.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb7f2df3-e963-4021-ac5a-5ccbb077e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This RPG sets a new benchmark for open - world exploration, with a vast cast of monsters each with their own unique moveset, secrets, puzzles and challenging bosses all with deeply woven lore and questlines. The map is vast end littered with surprises that will keep you busy throughout the game. From Software has truely made a unique and ambitious game that leaves you wanting more.\n",
      "This bar game sets a new benchmark for open-world exploration, with a sprawling experience gallery of diverse monsters quirks each with bosses their own encounters unique games moveset, secrets, packed puzzles and challenging bosses all with intricately woven lore and questlines. The map is vast end boss littered stories with content that will keep variety you traps engaged throughout the game. From Software has truely made a again compelling and challenging game RPG that leaves you wanting more.\n",
      "This puzzles sets a open engaged for moveset-world leaves, with a game gallery of woven each with their own unique benchmark, secrets, content and new exploration all with map monsters lore and challenging. The intricately is vast questlines littered with bosses that will keep you end throughout the game. From Software has truely made a compelling and challenging game that wanting you sprawling more.\n",
      "This game a benchmark for open world exploration, with a sprawling gallery of each with their own secrets and bosses all with intricately and questlines. The is with content that will keep you throughout the game. From has made a compelling and challenging that you wanting more.\n"
     ]
    }
   ],
   "source": [
    "print(synonym_replacement(test_1, 0.5))\n",
    "print(random_insertion(test_1, 0.5))\n",
    "print(random_swap(test_1, 0.5))\n",
    "print(random_deletion(test_1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a59e0-d0ba-4588-ba55-f21eff66121c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c2b33-4eb1-4ff7-ab9c-feca1b57b05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6914c-791f-4110-95f7-c3d9c2735db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace79b5-3edb-4f84-bf2b-cdc56254b5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6a86d5e8-f099-49b6-87c7-7719fd5d8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('train_1.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "enhanced_data = {}\n",
    "count = 0\n",
    "\n",
    "for review_id, review_data in data.items():\n",
    "    if count % 100 ==0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "    \n",
    "    enhanced_data[review_id] = review_data\n",
    "    text = review_data['text']\n",
    "\n",
    "    if review_data['audio'] == 1:\n",
    "        enhanced_data[review_id + '_sr'] = {\n",
    "            **review_data,\n",
    "            'text': synonym_replacement(text, 0.1)\n",
    "        }\n",
    "        enhanced_data[review_id + '_ri'] = {\n",
    "            **review_data,\n",
    "            'text': random_insertion(text, 0.1)\n",
    "        }\n",
    "        enhanced_data[review_id + '_rw'] = {\n",
    "            **review_data,\n",
    "            'text': random_swap(text, 0.1)\n",
    "        }\n",
    "        enhanced_data[review_id + '_rd'] = {\n",
    "            **review_data,\n",
    "            'text': random_deletion(text, 0.1)\n",
    "        }\n",
    "    elif review_data['items'] == 1 or review_data['narrative'] == 1:\n",
    "        enhanced_data[review_id + '_sr'] = {\n",
    "            **review_data,\n",
    "            'text': synonym_replacement(text, 0.1)\n",
    "        }\n",
    "        enhanced_data[review_id + '_ri'] = {\n",
    "            **review_data,\n",
    "            'text': random_insertion(text, 0.1)\n",
    "        }\n",
    "    \n",
    "\n",
    "with open('train_3.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(enhanced_data, file, indent=4)\n",
    "print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dea7f-ffa8-4199-a353-72448d958a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
